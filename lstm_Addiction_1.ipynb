{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BS7bgOzU1tTn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer # for stemming\n",
        "from nltk.stem import WordNetLemmatizer # for lemmatization\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split , cross_val_score,KFold\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "!pip install imblearn\n",
        "import imblearn\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duLsZGV-RPiJ"
      },
      "outputs": [],
      "source": [
        "!pip install keras\n",
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kTfqelA6ID6"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
        "from keras.layers import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "#import os\n",
        "#print(os.listdir(\"../input\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "from keras.models import Sequential\n",
        "#from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "#%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akfTWY4kSg_K"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qXQe8yf37oQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "#df = pd.read_fwf('/content/drive/MyDrive/temp_files/hate and offensive/train.txt', sep=\" \", header=None, names=[ \"id\", \"label\", \"tweet\"] , encoding='UTF-8')\n",
        "df = pd.read_fwf('train.txt', sep=\" \", header=None, names=[ \"id\", \"label\", \"tweet\"] , encoding='UTF-8')\n",
        "# data=data[900:1100]\n",
        "data_text = df[['tweet']]\n",
        "data_text = data_text.astype('str')\n",
        "\n",
        "tweets = []\n",
        "for index, row in data_text.iterrows():\n",
        "    tweets.append(row['tweet'])\n",
        "\n",
        "print('Size of dataset:',len(tweets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJE9v4z7Bi8c"
      },
      "outputs": [],
      "source": [
        "df['label'].unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-msctDISW7H"
      },
      "outputs": [],
      "source": [
        "x = df['tweet']\n",
        "y = df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4Sdxm7dSfx7"
      },
      "outputs": [],
      "source": [
        "token = Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEjKODU5Sh4F"
      },
      "outputs": [],
      "source": [
        "token.fit_on_texts(x)\n",
        "seq = token.texts_to_sequences(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znxfAcnsSk5J"
      },
      "outputs": [],
      "source": [
        "pad_seq = pad_sequences(seq,maxlen=300)\n",
        "vocab_size = len(token.word_index)+1\n",
        "x = df['tweet']\n",
        "y = df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcsRHrhG8ZNm"
      },
      "outputs": [],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTnd1CC835x9"
      },
      "outputs": [],
      "source": [
        "from keras.initializers import Constant\n",
        "from tensorflow.keras.preprocessing.text import one_hot,Tokenizer\n",
        "\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "#from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils import pad_sequences\n",
        "embedding_vector = {}\n",
        "f=open(\"glove.6B.100d.txt\",encoding=\"utf-8\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rbPuEj5m24f"
      },
      "outputs": [],
      "source": [
        "for line in tqdm(f):\n",
        "    value = line.split(' ')\n",
        "    word = value[0]\n",
        "    coef = np.array(value[1:],dtype = 'float32')\n",
        "    embedding_vector[word] = coef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBFltuo2StR2"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = np.zeros((vocab_size,100))\n",
        "for word,i in tqdm(token.word_index.items()):\n",
        "    embedding_value = embedding_vector.get(word)\n",
        "    if embedding_value is not None:\n",
        "        embedding_matrix[i] = embedding_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvwxflPs0nD5"
      },
      "outputs": [],
      "source": [
        "y = df['label']\n",
        "counter = Counter(y)\n",
        "for k,v in counter.items():\n",
        " per = v / len(y) * 100\n",
        " print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
        "# plot the distribution\n",
        "plt.bar(counter.keys(), counter.values())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWSRRhvv7QxX"
      },
      "outputs": [],
      "source": [
        "modelLSTMGL = Sequential()\n",
        "modelLSTMGL.add(Embedding(vocab_size,100,weights = [embedding_matrix],input_length=300,trainable = False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onTtw9Ii0sR-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(pad_seq, y, test_size=0.15,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9rZsEad2k_k"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
        "from keras.layers import Embedding,Bidirectional\n",
        "from keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK7mJLS-8h0-"
      },
      "outputs": [],
      "source": [
        "modelLSTMGL = Sequential()\n",
        "modelLSTMGL.add(Embedding(vocab_size,100,weights = [embedding_matrix],input_length=300,trainable = False))\n",
        "modelLSTMGL.add(Bidirectional(LSTM(25)))\n",
        "modelLSTMGL.add(Dense(16,activation = 'relu'))\n",
        "modelLSTMGL.add(Dense(1,activation = 'sigmoid'))\n",
        "modelLSTMGL.compile(optimizer='adam',loss='binary_crossentropy',metrics = ['accuracy'])\n",
        "history = modelLSTMGL.fit(pad_seq, y,epochs = 5,batch_size=32,validation_split=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy1b6L0S8kcP"
      },
      "outputs": [],
      "source": [
        "values = history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jWtH7lg8nnm"
      },
      "outputs": [],
      "source": [
        "\n",
        "val_loss = values['val_loss']\n",
        "training_loss = values['loss']\n",
        "training_acc = values['accuracy']\n",
        "validation_acc = values['val_accuracy']\n",
        "epochs = range(5)\n",
        "\n",
        "plt.plot(epochs,val_loss,label = 'Validation Loss')\n",
        "plt.plot(epochs,training_loss,label = 'Training Loss')\n",
        "plt.title('LSTM+GLOVE Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(epochs,validation_acc,label = 'Validation Accuracy')\n",
        "plt.plot(epochs,training_acc,label = 'Training Accuracy')\n",
        "plt.title('LSTM+GLOVE Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svYpraMG9IFg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score,recall_score,accuracy_score, f1_score\n",
        "def show_confusion(label,pred_label,nm):\n",
        "  class_names=['No-Addiction','Addiction']\n",
        "  cm=confusion_matrix(label,pred_label)\n",
        "  disp =ConfusionMatrixDisplay(cm,display_labels=class_names)\n",
        "  disp.plot()\n",
        "  plt.title(f'Confusion Matrix {nm} ')\n",
        "\n",
        "  plt.xlabel('Actual labels')\n",
        "  plt.ylabel('Predicted labels')\n",
        "  plt.show()\n",
        "\n",
        "def mymetrics(Y,P,alg = None):\n",
        "    recall= recall_score(Y, P)\n",
        "    acc2= accuracy_score(Y, P)\n",
        "    precision= precision_score(Y, P)\n",
        "    Fmeasure = f1_score(Y, P)\n",
        "    print(f\"accuracy = {acc2*100}\")\n",
        "    print(f'recall= {recall*100}')\n",
        "    print(f'precision= {precision*100}')\n",
        "    print(f'Fmeasure= {Fmeasure*100}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvFianoRy_AV"
      },
      "outputs": [],
      "source": [
        "ptrLstm = modelLSTMGL.predict(X_train)\n",
        "ptsLstm = modelLSTMGL.predict(X_test)\n",
        "ptrLstm=(ptrLstm>0.5)\n",
        "ptsLstm=(ptsLstm>0.5)\n",
        "ptrLstm=ptrLstm.astype(float)\n",
        "ptsLstm=ptsLstm.astype(float)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD1tb20UTfF5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNuQlGjvO-dv"
      },
      "outputs": [],
      "source": [
        "c = classification_report(y_test,ptsLstm,digits=4)\n",
        "\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw_UShwYPHm4"
      },
      "outputs": [],
      "source": [
        "print(\"===== : Validation Lstm+Glove : =====\")\n",
        "mymetrics(y_test,ptsLstm,'Validation Lstm+Glove')\n",
        "show_confusion(ptsLstm,y_test,'Validation Lstm+Glove')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCTIf1wt8sDT"
      },
      "outputs": [],
      "source": [
        "\n",
        "#testing = pd.read_fwf('/content/drive/MyDrive/temp_files/hate and offensive/test.txt', sep=\" \", header=None, names=[ \"id\", \"label\", \"tweet\"] , encoding='UTF-8')\n",
        "testing = pd.read_fwf('test.txt', sep=\" \", header=None, names=[ \"id\",\"label\", \"tweet\"] , encoding='utf-8')\n",
        "\n",
        "testing.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pcw5fk2UbG20"
      },
      "outputs": [],
      "source": [
        "x_test = testing['tweet']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SFeF8YhbFuP"
      },
      "outputs": [],
      "source": [
        "x_test = token.texts_to_sequences(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xB_YfCbd8vrB"
      },
      "outputs": [],
      "source": [
        "testing_seq = pad_sequences(x_test,maxlen=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrfUtjFW80Ic"
      },
      "outputs": [],
      "source": [
        "predic = modelLSTMGL.predict(testing_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWxQsF-veU2Z"
      },
      "outputs": [],
      "source": [
        "# preds=[]\n",
        "# for i in predict:\n",
        "#   preds.append(0 if i<0.5 else 1)\n",
        "preds=(predic>0.5)\n",
        "preds=preds.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycjdfscbTnH3"
      },
      "outputs": [],
      "source": [
        "z = classification_report(testing['label'], preds,digits=4)\n",
        "\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8R8ir1cjVPD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "print()\n",
        "print(\" precision: {}\".format(precision_score(testing['label'], preds)))\n",
        "print(\" recall: {}\".format(recall_score(testing['label'], preds)))\n",
        "print(\" Accuracy: {}\".format(accuracy_score(testing['label'], preds)))\n",
        "print(\" f1: {}\".format(f1_score(testing['label'], preds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tZQNb4zbb3j"
      },
      "outputs": [],
      "source": [
        "print(\"===== : Test Lstm+Glove : =====\")\n",
        "mymetrics(preds,testing['label'])\n",
        "show_confusion(preds,testing['label'] ,'Test Lstm+Glove')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXIg_95e84er"
      },
      "outputs": [],
      "source": [
        "submit_df = pd.DataFrame({\"id\": testing[\"id\"], \"prediction\": testing['label']})\n",
        "submit_df.to_csv(\"submission.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}